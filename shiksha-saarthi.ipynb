{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shiksha Saarthi: Advanced Multi-Agent Exam Preparation Tutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Overview**\n",
    "\n",
    "\n",
    "Track: Agents for Good\n",
    "\n",
    "\n",
    "Problem: Standard online learning is generic. Students preparing for high-stakes competitive exams (like GATE, NIMCET) need personalized, real-difficulty level coaching in their preferred language.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Solution: Shiksha Saarthi is a Multi-Agent system that acts as a specialized coach. It uses three distinct agents to provide adaptive, exam-specific lessons, detailed solutions, and continuous performance tracking.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-15T16:05:09.879227Z",
     "iopub.status.busy": "2025-11-15T16:05:09.878857Z",
     "iopub.status.idle": "2025-11-15T16:05:10.253911Z",
     "shell.execute_reply": "2025-11-15T16:05:10.253039Z",
     "shell.execute_reply.started": "2025-11-15T16:05:09.879205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:05:15.583667Z",
     "iopub.status.busy": "2025-11-15T16:05:15.582990Z",
     "iopub.status.idle": "2025-11-15T16:05:21.737117Z",
     "shell.execute_reply": "2025-11-15T16:05:21.735104Z",
     "shell.execute_reply.started": "2025-11-15T16:05:15.583637Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in /usr/local/lib/python3.11/dist-packages (1.48.0)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.11.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.38.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.12.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from google-genai) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: cachetools\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 6.2.1\n",
      "    Uninstalling cachetools-6.2.1:\n",
      "      Successfully uninstalled cachetools-6.2.1\n",
      "Successfully installed cachetools-5.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:05:24.312467Z",
     "iopub.status.busy": "2025-11-15T16:05:24.312089Z",
     "iopub.status.idle": "2025-11-15T16:05:24.570246Z",
     "shell.execute_reply": "2025-11-15T16:05:24.569000Z",
     "shell.execute_reply.started": "2025-11-15T16:05:24.312434Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini API Key successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# Load the API Key from Kaggle Secrets\n",
    "try:\n",
    "    secrets = UserSecretsClient()\n",
    "    os.environ[\"GEMINI_API_KEY\"] = secrets.get_secret(\"GEMINI_API_KEY\") \n",
    "    print(\"Gemini API Key successfully loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading API Key: {e}\")\n",
    "    print(\"Please set GEMINI_API_KEY in Kaggle Secrets.\")\n",
    "    \n",
    "# Initialize the Gemini Client\n",
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent 2: Diagnostic Agent (Sessions & Memory)\n",
    "\n",
    "This agent is the system's memory.\n",
    "\n",
    "\n",
    "Function: It tracks the student's progress (score_total, question_count) and stores the complete Q&A history.\n",
    "\n",
    "Architecture Role: It informs the Teacher Agent whether the student needs a harder topic or remedial help (real-world context). (Fulfills Mandatory Feature: Sessions & Memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:05:29.177250Z",
     "iopub.status.busy": "2025-11-15T16:05:29.176853Z",
     "iopub.status.idle": "2025-11-15T16:05:29.188998Z",
     "shell.execute_reply": "2025-11-15T16:05:29.187862Z",
     "shell.execute_reply.started": "2025-11-15T16:05:29.177225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# DiagnosticAgent Code\n",
    "class DiagnosticAgent:\n",
    "    \"\"\"\n",
    "    Diagnostic Agent tracks the student's progress, including questions, answers, and results. (Memory Feature)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.student_data = {} \n",
    "\n",
    "    def retrieve_state(self, student_id):\n",
    "        return self.student_data.get(student_id, None)\n",
    "\n",
    "    def update_progress(self, student_id, topic, is_correct, question_asked=None, user_answer=None):\n",
    "        \"\"\" Updates progress based on the student's answer, saving the question and answer. \"\"\"\n",
    "        if student_id not in self.student_data:\n",
    "            self.student_data[student_id] = {\n",
    "                \"progress\": [],\n",
    "                \"current_topic\": topic,\n",
    "                \"score_total\": 0,\n",
    "                \"question_count\": 0\n",
    "            }\n",
    "            \n",
    "        data = self.student_data[student_id]\n",
    "        \n",
    "        # Detailed progress data is included here\n",
    "        data[\"progress\"].append({\n",
    "            \"topic\": topic,\n",
    "            \"question\": question_asked,\n",
    "            \"answer_given\": user_answer,\n",
    "            \"correct\": is_correct\n",
    "        })\n",
    "        \n",
    "        data[\"question_count\"] += 1\n",
    "        if is_correct:\n",
    "            data[\"score_total\"] += 1\n",
    "        \n",
    "        data[\"current_topic\"] = topic\n",
    "        \n",
    "    def analyze_and_suggest_next_step(self, student_id):\n",
    "        \"\"\" Suggests the next step for the Teacher Agent. \"\"\"\n",
    "        data = self.student_data.get(student_id)\n",
    "        \n",
    "        if not data or data[\"question_count\"] < 1:\n",
    "            return {\"next_topic\": \"Math: Basic Addition\", \"need_real_world_example\": False}\n",
    "        \n",
    "        score_percent = (data[\"score_total\"] / data[\"question_count\"]) * 100\n",
    "        current_topic_full = data[\"current_topic\"]\n",
    "        \n",
    "        try:\n",
    "            current_subject = current_topic_full.split(\":\")[0].strip()\n",
    "        except IndexError:\n",
    "             current_subject = \"Math\" \n",
    "\n",
    "        \n",
    "        if score_percent < 60:\n",
    "            # If the score is low, request help from Research Agent (stay on the same topic)\n",
    "            return {\n",
    "                \"next_topic\": current_topic_full,\n",
    "                \"confidence_score\": f\"{score_percent:.0f}%\",\n",
    "                \"need_real_world_example\": True, \n",
    "                \"reason\": \"Low score, needs more engaging content.\"\n",
    "            }\n",
    "        else:\n",
    "            # If the score is good, suggest moving to the next topic (based on subject)\n",
    "            if \"Science\" in current_subject:\n",
    "                next_topic = \"Science: The Water Cycle\"\n",
    "            elif \"History\" in current_subject:\n",
    "                 next_topic = \"History: Feudalism\"\n",
    "            else: # Math\n",
    "                next_topic = \"Math: Basic Fractions\"\n",
    "            \n",
    "            return {\n",
    "                \"next_topic\": next_topic, \n",
    "                \"confidence_score\": f\"{score_percent:.0f}%\",\n",
    "                \"need_real_world_example\": False,\n",
    "                \"reason\": \"Student shows good understanding, ready for next concept.\"\n",
    "            }\n",
    "\n",
    "diagnostic_agent = DiagnosticAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent 3: Research Agent (Tools Integration)\n",
    "\n",
    "This agent integrates external, real-time data.\n",
    "\n",
    "Function: It uses the Google Search Tool to fetch real-world examples (Class Mode) or confirm the required PYQ difficulty/syllabus context for the specific exam (Competitive Mode).\n",
    "\n",
    "Architecture Role: It provides contextual data to the Teacher Agent to make lessons more relevant. (Fulfills Mandatory Feature: Tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:05:34.271923Z",
     "iopub.status.busy": "2025-11-15T16:05:34.271573Z",
     "iopub.status.idle": "2025-11-15T16:05:34.281365Z",
     "shell.execute_reply": "2025-11-15T16:05:34.280057Z",
     "shell.execute_reply.started": "2025-11-15T16:05:34.271898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 3: ResearchAgent Code (CRITICAL FIX for Server Errors)\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.genai.errors import APIError, ServerError # IMPORT CRITICAL FOR HANDLING ERRORS\n",
    "\n",
    "class ResearchAgent:\n",
    "    \"\"\"\n",
    "    Research Agent finds external information using the Google Search Tool (Tools Feature).\n",
    "    \"\"\"\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.system_instruction = (\\\n",
    "            \"You are the Research Agent. Your only job is to receive a search query, \"\\\n",
    "            \"use the google_search tool to find information, and summarize the results \"\\\n",
    "            \"in a simple, child-friendly format (primary education level). \"\\\n",
    "            \"Your output must be the summarized text only.\"\\\n",
    "        )\n",
    "\n",
    "    def execute_search(self, search_query: str) -> str:\n",
    "        \"\"\" Executes the query using the Google Search Tool, with strict error handling. \"\"\"\n",
    "        \n",
    "        print(f\"\\n[Research Agent]: Attempting to search for '{search_query}'...\")\n",
    "        \n",
    "        try:\n",
    "            # Attempt to use the Gemini model with the Google Search Tool\n",
    "            response = self.client.models.generate_content(\n",
    "                model='gemini-2.5-flash',\n",
    "                contents=[\n",
    "                    self.system_instruction,\n",
    "                    f\"Please find a simple, real-world context for: {search_query}\"\n",
    "                ],\n",
    "                config=types.GenerateContentConfig(\n",
    "                    tools=[{\"google_search\": {}}] \n",
    "                )\n",
    "            )\n",
    "            \n",
    "            if response.text:\n",
    "                print(\"[Research Agent]: Summary generated successfully.\")\n",
    "                return response.text\n",
    "            else:\n",
    "                print(\"[Research Agent]: Could not generate a summary (no text returned).\")\n",
    "                return \"Context search failed: Could not generate a summary.\"\n",
    "\n",
    "        # CATCH ALL API AND SERVER ERRORS! (THIS IS THE FIX)\n",
    "        except (APIError, ServerError, Exception) as e:\n",
    "            # CRITICAL FALLBACK: If the API call fails, return a safe string immediately.\n",
    "            print(f\"[Research Agent CRITICAL ERROR]: Search failed. Returning default context. Error: {e}\")\n",
    "            return \"Context search failed: Returning a generic internal example due to an external server error.\"\n",
    "\n",
    "research_agent = ResearchAgent(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent 4: Teacher Agent (Multi-Agent Coordinator)\n",
    "\n",
    "This is the core LLM-powered agent and the system coordinator.\n",
    "\n",
    "Function: It orchestrates the flow: 1. Gets next step from Diagnostic Agent. 2. Requests context from Research Agent. 3. Generates the final lesson/question using advanced prompts for the chosen mode (Class/Competitive).\n",
    "\n",
    "Architecture Role: It demonstrates the system's Sequential Agent structure. (Fulfills Mandatory Feature: Multi-agent system)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:05:38.607645Z",
     "iopub.status.busy": "2025-11-15T16:05:38.607312Z",
     "iopub.status.idle": "2025-11-15T16:05:38.622008Z",
     "shell.execute_reply": "2025-11-15T16:05:38.620304Z",
     "shell.execute_reply.started": "2025-11-15T16:05:38.607620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# TeacherAgent Code\n",
    "class TeacherAgent:\n",
    "    \"\"\"\n",
    "    Teacher Agent handles the main conversation and is the core of the Multi-Agent System.\n",
    "    \"\"\"\n",
    "    def __init__(self, client, diagnostic_agent, research_agent):\n",
    "        self.client = client\n",
    "        self.diagnostic_agent = diagnostic_agent\n",
    "        self.research_agent = research_agent\n",
    "        self.student_id = \"live_student\" \n",
    "        self.current_topic = None \n",
    "        \n",
    "        self.system_instruction = (\n",
    "            \"You are the Teacher Agent, 'Shiksha Saarthi.' You are teaching primary school concepts. \"\n",
    "            \"Be patient, encouraging, and always follow the instructions given by the Diagnostic Agent for the next lesson.\"\n",
    "        )\n",
    "\n",
    "    def start_session(self, mode, language, exam_name=None): \n",
    "        \"\"\" Starts the session and coordinates the next lesson/question. \"\"\"\n",
    "        \n",
    "        suggestion = self.diagnostic_agent.analyze_and_suggest_next_step(self.student_id)\n",
    "        next_topic = suggestion[\"next_topic\"]\n",
    "        self.current_topic = next_topic \n",
    "        \n",
    "        print(f\"\\n[DIAGNOSTICS]: Suggested next topic is: {next_topic}\")\n",
    "        \n",
    "        extra_context = None\n",
    "        \n",
    "        # Research Agent usage for Competitive Mode\n",
    "        if mode == \"Competitive\":\n",
    "            search_query = f\"Previous year question example for {next_topic} in {exam_name}\"\n",
    "            extra_context = self.research_agent.execute_search(search_query)\n",
    "            print(f\"[TEACHER]: Using competitive context from Research Agent.\")\n",
    "            \n",
    "        elif suggestion[\"need_real_world_example\"]:\n",
    "            # Research Agent usage for improvement in Class Mode\n",
    "            search_query = f\"Simple real-world examples for {next_topic}\"\n",
    "            extra_context = self.research_agent.execute_search(search_query)\n",
    "            \n",
    "        # Pass language to generate_lesson\n",
    "        return self.generate_lesson(next_topic, mode, language, exam_name, extra_context=extra_context)\n",
    "\n",
    "\n",
    "    def generate_lesson(self, topic, mode, language, exam_name=None, extra_context=None):\n",
    "        \"\"\" Generates the lesson/question using Gemini, adapting based on mode and language. \"\"\"\n",
    "        \n",
    "        # Add language instruction to the top of the prompt\n",
    "        language_instruction = f\"All output MUST be in {language} language.\"\n",
    "        \n",
    "        if mode == \"Competitive\":\n",
    "            # Detailed prompt for Competitive Mode\n",
    "            prompt = (\n",
    "                f\"{language_instruction} Topic: {topic}. You are acting as an expert coach for the {exam_name} exam. \"\n",
    "                \"The question must match the REAL difficulty level of {exam_name}.\"\n",
    "                \"First, provide a brief, exam-focused concept review (padhai). \"\n",
    "                \"Then, ask ONE challenging question. \"\n",
    "                \"If the student answers incorrectly, you MUST provide a step-by-step, exact solution and explanation (samjha ke) like an expert would.\"\n",
    "            )\n",
    "        else:\n",
    "            # Prompt for Class Mode (Default)\n",
    "            prompt = (\n",
    "                f\"{language_instruction} Topic: {topic}. You are acting as a school teacher. \"\n",
    "                \"Create a simple lesson and ask one question that tests this basic concept.\"\n",
    "            )\n",
    "\n",
    "        if extra_context:\n",
    "            prompt += f\"\\n\\nUse this context (Research Agent found PYQ/Syllabus info): {extra_context}\"\n",
    "            \n",
    "        \n",
    "        lesson_response = self.client.models.generate_content(\n",
    "            model='gemini-2.5-flash',\n",
    "            contents=[self.system_instruction, prompt]\n",
    "        )\n",
    "        return lesson_response.text\n",
    "\n",
    "    def evaluate_answer(self, user_answer, question_text, language): \n",
    "        \"\"\" Evaluates the student's answer. \"\"\"\n",
    "        \n",
    "        topic = self.current_topic \n",
    "        \n",
    "        evaluation_prompt = (\n",
    "            f\"All feedback and responses MUST be in {language} language. Topic: {topic}. Student's answer: '{user_answer}'. \"\n",
    "            \"Did the student understand the core concept? Respond with only the word TRUE or FALSE (first line), and provide encouraging feedback (second line).\"\n",
    "        )\n",
    "        \n",
    "        evaluation_response = self.client.models.generate_content(\n",
    "            model='gemini-2.5-flash',\n",
    "            contents=[self.system_instruction, evaluation_prompt] \n",
    "        )\n",
    "        \n",
    "        is_correct = \"TRUE\" in evaluation_response.text.split('\\n')[0].upper()\n",
    "        \n",
    "        # Send data to the Diagnostic Agent\n",
    "        self.diagnostic_agent.update_progress(\n",
    "            self.student_id, \n",
    "            topic, \n",
    "            is_correct, \n",
    "            question_asked=question_text,  \n",
    "            user_answer=user_answer\n",
    "        )\n",
    "        \n",
    "        return is_correct, evaluation_response.text\n",
    "\n",
    "    def get_current_topic(self):\n",
    "        return self.current_topic\n",
    "        \n",
    "    def get_diagnostic_report(self):\n",
    "        return self.diagnostic_agent.retrieve_state(self.student_id)\n",
    "\n",
    "teacher_agent = TeacherAgent(client, diagnostic_agent, research_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System Architecture Flow\n",
    "\n",
    "\n",
    "Your system operates sequentially:\n",
    "\n",
    "1. User Input (Mode, Language, Topic).\n",
    "\n",
    "\n",
    "2. Teacher Agent queries Diagnostic Agent for next step.\n",
    "\n",
    "\n",
    "3. Teacher Agent queries Research Agent for real-time context/PYQ.\n",
    "\n",
    "\n",
    "4. Teacher Agent uses all context to generate the lesson/question.\n",
    "\n",
    "\n",
    "5. Teacher Agent evaluates the answer and updates Diagnostic Agent memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:05:42.298184Z",
     "iopub.status.busy": "2025-11-15T16:05:42.297840Z",
     "iopub.status.idle": "2025-11-15T16:06:53.985141Z",
     "shell.execute_reply": "2025-11-15T16:06:53.984183Z",
     "shell.execute_reply.started": "2025-11-15T16:05:42.298161Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "ü§ñ Shiksha Saarthi (Interactive Session) üöÄ\n",
      "Type 'exit' or 'quit' to end the session at any time.\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In which language would you like to study (e.g., Hindi, English)?  english\n",
      "Which mode would you like to use (Class/Competitive)?  class\n",
      "Which subject would you like to study?  computer\n",
      "Which topic in Computer would you like to study (Press Enter for default: Basic Concepts)?  Ai Ml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Class session for: Computer: Ai Ml in english (Exam: None)...\n",
      "\n",
      "\n",
      "[DIAGNOSTICS]: Suggested next topic is: Computer: Ai Ml\n",
      "\n",
      "[Research Agent]: Attempting to search for 'Simple real-world examples for Computer: Ai Ml'...\n",
      "[Research Agent]: Summary generated successfully.\n",
      "\n",
      "[TEACHER]: Hello, my wonderful students! I'm Shiksha Saarthi, and I'm so excited to learn with you today!\n",
      "\n",
      "Today, we're going to talk about something really amazing that computers can do. Imagine if your computer could almost **think** and **learn** new things, just like you do! Isn't that super cool? Well, that's what we call **Artificial Intelligence (AI)** and **Machine Learning (ML)**. Don't worry about the big words, let's think of them as ways computers get super smart!\n",
      "\n",
      "Think of it like this:\n",
      "\n",
      "*   **Talking to computers:** Have you ever heard your grown-ups talk to a smart speaker like Alexa or Siri, and ask it questions or tell it to play a song? That's AI! The computer listens to your words, understands them, and tries to help. The more people talk to it, the smarter it gets at understanding!\n",
      "*   **Getting suggestions:** When you watch your favourite cartoons on a tablet, sometimes it suggests other videos you might like. How does it know? That's AI and ML! The computer learns what you enjoy and helps you find more of it. It's like having a friend who knows all your favourite things!\n",
      "*   **Finding your way:** When your parents use a map app on their phone to find the quickest way to your friend's house, even if there's traffic, AI helps the computer figure out the best roads. It's like a super smart guide!\n",
      "*   **Sorting pictures:** Imagine your phone helping you put all your dog pictures in one group, or all your birthday party pictures together. AI can do that! It learns to recognize what's in your photos.\n",
      "\n",
      "So, AI and ML are just special ways we teach computers to be super helpers. They learn from information and get better at tasks, making our lives easier and more fun!\n",
      "\n",
      "Are you ready for a little question, my clever learners?\n",
      "\n",
      "---\n",
      "\n",
      "Now, can you tell me which of these things a computer using AI or ML can help us do?\n",
      "\n",
      "A) Sleep at night\n",
      "B) Understand when you talk to Alexa or Siri\n",
      "C) Eat your food\n",
      "D) Play in the park\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STUDENT]:  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating answer for topic: Computer: Ai Ml...\n",
      "\n",
      "[TEACHER FEEDBACK]: TRUE\n",
      "Wonderful job! You're showing great understanding of this exciting topic.\n",
      "Diagnostic Result: Correct\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to continue to the next question? (Y/N or Exit):  N\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you! Your session has ended.\n",
      "\n",
      "--- FINAL DIAGNOSTIC REPORT ---\n",
      "Student ID: live_student\n",
      "{\n",
      "    \"progress\": [\n",
      "        {\n",
      "            \"topic\": \"Computer: Ai Ml\",\n",
      "            \"question\": \"Session Start\",\n",
      "            \"answer_given\": \"N/A\",\n",
      "            \"correct\": false\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer: Ai Ml\",\n",
      "            \"question\": \"Hello, my wonderful students! I'm Shiksha Saarthi, and I'm so excited to learn with you today!\\n\\nToday, we're going to talk about something really amazing that computers can do. Imagine if your computer could almost **think** and **learn** new things, just like you do! Isn't that super cool? Well, that's what we call **Artificial Intelligence (AI)** and **Machine Learning (ML)**. Don't worry about the big words, let's think of them as ways computers get super smart!\\n\\nThink of it like this:\\n\\n*   **Talking to computers:** Have you ever heard your grown-ups talk to a smart speaker like Alexa or Siri, and ask it questions or tell it to play a song? That's AI! The computer listens to your words, understands them, and tries to help. The more people talk to it, the smarter it gets at understanding!\\n*   **Getting suggestions:** When you watch your favourite cartoons on a tablet, sometimes it suggests other videos you might like. How does it know? That's AI and ML! The computer learns what you enjoy and helps you find more of it. It's like having a friend who knows all your favourite things!\\n*   **Finding your way:** When your parents use a map app on their phone to find the quickest way to your friend's house, even if there's traffic, AI helps the computer figure out the best roads. It's like a super smart guide!\\n*   **Sorting pictures:** Imagine your phone helping you put all your dog pictures in one group, or all your birthday party pictures together. AI can do that! It learns to recognize what's in your photos.\\n\\nSo, AI and ML are just special ways we teach computers to be super helpers. They learn from information and get better at tasks, making our lives easier and more fun!\\n\\nAre you ready for a little question, my clever learners?\\n\\n---\\n\\nNow, can you tell me which of these things a computer using AI or ML can help us do?\\n\\nA) Sleep at night\\nB) Understand when you talk to Alexa or Siri\\nC) Eat your food\\nD) Play in the park\",\n",
      "            \"answer_given\": \"c\",\n",
      "            \"correct\": true\n",
      "        }\n",
      "    ],\n",
      "    \"current_topic\": \"Computer: Ai Ml\",\n",
      "    \"score_total\": 1,\n",
      "    \"question_count\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --- Interactive Chat Loop (PURE INTERACTIVE MODE with Y/N Check) ---\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Dictionary of subjects and their initial topics\n",
    "DEFAULT_TOPICS = {\n",
    "    \"math\": \"Basic Addition\",\n",
    "    \"science\": \"Basic Plants/Animals\",\n",
    "    \"history\": \"Ancient Civilizations\",\n",
    "    \"analytical ability\": \"Basic Reasoning\",\n",
    "    \"computer awareness\": \"Basic Terminology\",\n",
    "    \"english\": \"Basic Grammar\"\n",
    "}\n",
    "\n",
    "# In pure interactive mode, we don't need mock input logic.\n",
    "def mock_input(prompt):\n",
    "    return \"exit\"\n",
    "\n",
    "def interactive_chat_loop(is_notebook_save=False):\n",
    "    # --- PURE INTERACTIVE SETUP ---\n",
    "    # We ignore the save check and force input_func to be the real 'input'.\n",
    "    input_func = input\n",
    "    is_notebook_save = False \n",
    "    # --- END PURE INTERACTIVE SETUP ---\n",
    "    \n",
    "    print(\"-----------------------------------------------------\")\n",
    "    print(\"ü§ñ Shiksha Saarthi (Interactive Session) üöÄ\")\n",
    "    print(\"Type 'exit' or 'quit' to end the session at any time.\") \n",
    "    print(\"-----------------------------------------------------\")\n",
    "\n",
    "\n",
    "    # --- 0. Language Selection (OLD FLOW) ---\n",
    "    session_language = input_func(\"In which language would you like to study (e.g., Hindi, English)? \").strip()\n",
    "    if not session_language:\n",
    "        session_language = \"English\"\n",
    "        print(f\"Default language: {session_language} selected.\")\n",
    "\n",
    "    # --- 1. Mode Selection (OLD FLOW) ---\n",
    "    exam_name = None\n",
    "    while True:\n",
    "        mode_choice = input_func(\"Which mode would you like to use (Class/Competitive)? \").strip()\n",
    "        if mode_choice.lower() == 'class':\n",
    "            session_mode = 'Class'\n",
    "            break\n",
    "        elif mode_choice.lower() == 'competitive':\n",
    "            session_mode = 'Competitive'\n",
    "            exam_name = input_func(\"Which Competitive Exam are you preparing for (e.g., GATE, NIMCET, CTPG)? \").strip()\n",
    "            if not exam_name:\n",
    "                exam_name = \"Generic Competitive Exam\" \n",
    "            break\n",
    "        else:\n",
    "            print(\"‚ùå Please choose either Class or Competitive.\")\n",
    "\n",
    "    # --- 2. Subject Selection (OLD FLOW) ---\n",
    "    subject_choice = input_func(\"Which subject would you like to study? \").strip()\n",
    "    subject_key = subject_choice.lower()\n",
    "    initial_subject = subject_key.capitalize()\n",
    "\n",
    "    # --- 3. Topic Selection (OLD FLOW) ---\n",
    "    default_topic = DEFAULT_TOPICS.get(subject_key, \"Basic Concepts\")\n",
    "    topic_choice = input_func(f\"Which topic in {initial_subject} would you like to study (Press Enter for default: {default_topic})? \").strip()\n",
    "\n",
    "    if not topic_choice:\n",
    "        initial_topic = f\"{initial_subject}: {default_topic}\"\n",
    "    else:\n",
    "        initial_topic = f\"{initial_subject}: {topic_choice.strip()}\"\n",
    "\n",
    "    print(f\"\\nStarting {session_mode} session for: {initial_topic} in {session_language} (Exam: {exam_name})...\\n\")\n",
    "\n",
    "    # Set the Diagnostic Agent's memory (initial dummy entry)\n",
    "    teacher_agent.diagnostic_agent.update_progress(teacher_agent.student_id, initial_topic, False, question_asked=\"Session Start\", user_answer=\"N/A\")\n",
    "    teacher_agent.current_topic = initial_topic \n",
    "\n",
    "    # 4. Get the first lesson\n",
    "    previous_lesson = teacher_agent.start_session(session_mode, session_language, exam_name) \n",
    "    print(\"\\n[TEACHER]: \" + previous_lesson)\n",
    "\n",
    "    # Conversation loop\n",
    "    while True:\n",
    "        try:\n",
    "            # Determine user input (only real input is used here)\n",
    "            user_input = input_func(\"\\n[STUDENT]: \") # <--- ‡§∏‡§ø‡§Ç‡§ó‡§≤ ‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü ‡§ú‡•à‡§∏‡§æ ‡§Ü‡§™ ‡§ö‡§æ‡§π‡§§‡•á ‡§•‡•á\n",
    "            \n",
    "            # --- 1. EXIT LOGIC (Answer Box Exit) ---\n",
    "            if user_input.lower() in ['exit', 'quit']:\n",
    "                print(\"\\nThank you! Your session has ended.\")\n",
    "                print(\"\\n--- FINAL DIAGNOSTIC REPORT ---\")\n",
    "                print(f\"Student ID: {teacher_agent.student_id}\")\n",
    "                \n",
    "                print(json.dumps(teacher_agent.get_diagnostic_report(), indent=4)) \n",
    "                break \n",
    "\n",
    "\n",
    "            # 5. Evaluate the answer\n",
    "            print(f\"\\nEvaluating answer for topic: {teacher_agent.get_current_topic()}...\")\n",
    "            \n",
    "            is_correct, feedback = teacher_agent.evaluate_answer(user_input, previous_lesson, session_language)\n",
    "            \n",
    "            print(\"\\n[TEACHER FEEDBACK]: \" + feedback)\n",
    "            print(f\"Diagnostic Result: {'Correct' if is_correct else 'Incorrect'}\\n\")\n",
    "            \n",
    "            \n",
    "            # --- 2. Y/N CHECK BEFORE NEXT QUESTION (‡§®‡§Ø‡§æ ‡§∏‡•Å‡§ß‡§æ‡§∞) ---\n",
    "            \n",
    "            continue_action = input_func(\"Do you want to continue to the next question? (Y/N or Exit): \").strip().lower()\n",
    "            \n",
    "            if continue_action in ['n', 'exit', 'quit']:\n",
    "                print(\"\\nThank you! Your session has ended.\")\n",
    "                print(\"\\n--- FINAL DIAGNOSTIC REPORT ---\")\n",
    "                print(f\"Student ID: {teacher_agent.student_id}\")\n",
    "                print(json.dumps(teacher_agent.get_diagnostic_report(), indent=4))\n",
    "                break # Exit here\n",
    "\n",
    "            elif continue_action != 'y':\n",
    "                print(\"Invalid input. Continuing to the next question.\")\n",
    "\n",
    "\n",
    "            # 6. Ask for the next step \n",
    "            print(\"\\n--- Next Lesson/Question ---\")\n",
    "            next_lesson = teacher_agent.start_session(session_mode, session_language, exam_name) \n",
    "            previous_lesson = next_lesson\n",
    "            print(\"\\n[TEACHER]: \" + next_lesson)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Catch any error\n",
    "            print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "            print(\"\\n--- ATTEMPTING FINAL DIAGNOSTIC REPORT BEFORE CRASH ---\")\n",
    "            print(json.dumps(teacher_agent.get_diagnostic_report(), indent=4)) \n",
    "            break\n",
    "\n",
    "# Start the interactive session. \n",
    "interactive_chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Differentiating Features\n",
    "\n",
    "These advanced features distinguish Shiksha Saarthi:\n",
    "\n",
    "1. Exam-Specific Coaching: Uses the exam name (e.g., NIMCET) to ensure the question difficulty and content review are accurate and real-world competitive exam standards.\n",
    "\n",
    "\n",
    "2. Contextual Solutions: If the student answers incorrectly, the agent is prompted to provide a detailed, step-by-step explanatory solution (samjha ke) instead of just feedback.\n",
    "\n",
    "\n",
    "3. Multilingual Interface: The entire session can be conducted in the language of the student's choice (e.g., Hindi, English, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Demonstration: Final Diagnostic Report\n",
    "\n",
    "The JSON output below proves that the Diagnostic Agent successfully tracked the entire Q&A session, demonstrating the Sessions & Memory feature. It logs the full history, including questions and answers, and updates the score.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"progress\": [\n",
    "        {\n",
    "            \"topic\": \"Math: lcm\",\n",
    "            \"question\": null,\n",
    "            \"answer_given\": null,\n",
    "            \"correct\": false\n",
    "        },\n",
    "        {\n",
    "            \"topic\": \"Math: probability\",\n",
    "            \"question\": null,\n",
    "            \"answer_given\": null,\n",
    "            \"correct\": false\n",
    "        },\n",
    "        {\n",
    "            \"topic\": \"Math: probability\",\n",
    "            \"question\": \"Hello everyone! I am Shiksha Saarthi... [Question about apples and bananas]\",\n",
    "            \"answer_given\": \"impossible\",\n",
    "            \"correct\": true\n",
    "        },\n",
    "        {\n",
    "            \"topic\": \"Math: probability\",\n",
    "            \"question\": \"Hello, my little mathematicians! I'm your teacher... [Question about mouse baking a cake]\",\n",
    "            \"answer_given\": \"A\",\n",
    "            \"correct\": false\n",
    "        }\n",
    "    ],\n",
    "    \"current_topic\": \"Math: probability\",\n",
    "    \"score_total\": 1,\n",
    "    \"question_count\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
